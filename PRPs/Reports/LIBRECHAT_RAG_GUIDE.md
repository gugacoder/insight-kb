# Ponto de InterceptaÃ§Ã£o para RAG Middleware

## Ponto Exato para InterceptaÃ§Ã£o das TransaÃ§Ãµes com o LLM

### **ğŸ“ Local Principal de InterceptaÃ§Ã£o:**

**`/home/coder/insight-kb/api/app/clients/BaseClient.js:567`** - MÃ©todo `async sendMessage()`

Este Ã© o ponto central onde a MAIORIA das requisiÃ§Ãµes ao LLM passam antes de serem processadas. As seguintes implementaÃ§Ãµes herdam desta classe base:
- âœ… **OpenAI** (OpenAIClient)
- âœ… **Anthropic** (AnthropicClient)
- âœ… **Google** (GoogleClient)
- âœ… **Custom Endpoints** (via BaseClient)
- âœ… **Agents** (AgentClient)
- âš ï¸ **Assistants** - USA FLUXO DIFERENTE (OpenAI Assistants API)

### **ğŸ”„ Fluxo da RequisiÃ§Ã£o:**

1. **Entrada:** POST request â†’ `/api/agents/chat` (ou outros endpoints)
2. **Middleware:** `buildEndpointOption.js:31` - ConstrÃ³i opÃ§Ãµes do endpoint
3. **Controller:** `agents/request.js:184` - Chama `client.sendMessage()`
4. **BaseClient:** `BaseClient.js:567` - **PONTO DE INTERCEPTAÃ‡ÃƒO IDEAL**

### **ğŸ’¡ Como Implementar a InterceptaÃ§Ã£o:**

No mÃ©todo `sendMessage` em `BaseClient.js:567-571`, vocÃª pode injetar seu cÃ³digo assim:

```javascript
async sendMessage(message, opts = {}) {
  // âš¡ AQUI - Antes de processar a mensagem
  // Interceptar e enriquecer com dados do quadrante
  
  // 1. Fazer consulta ao quadrante
  // 2. Obter embeddings relevantes  
  // 3. Injetar contexto adicional na mensagem
  
  const enrichedMessage = await this.enrichMessageWithQuadrant(message);
  
  // Continua o fluxo normal...
  const { user, head, isEdited, conversationId, responseMessageId, saveOptions, userMessage } =
    await this.handleStartMethods(enrichedMessage, opts);
```

### **ğŸ¯ Por que este Ã© o melhor ponto:**

1. **Centralizado:** Todos os providers (OpenAI, Anthropic, etc.) passam por aqui
2. **PrÃ©-processamento:** Ocorre ANTES da mensagem ser enviada ao LLM
3. **Acesso completo:** Tem acesso a todo contexto da conversa e configuraÃ§Ãµes
4. **NÃ£o invasivo:** ModificaÃ§Ã£o mÃ­nima no cÃ³digo existente

### **ğŸ“Š Estruturas de Dados DisponÃ­veis:**

No ponto de interceptaÃ§Ã£o vocÃª terÃ¡ acesso a:
- `message`: Texto da mensagem do usuÃ¡rio
- `opts`: OpÃ§Ãµes incluindo `conversationId`, `parentMessageId`, contexto
- `this.currentMessages`: HistÃ³rico completo da conversa
- `this.options`: ConfiguraÃ§Ãµes do cliente/modelo

### **ğŸ”— Arquivos Relacionados:**

- **BaseClient:** `/api/app/clients/BaseClient.js` - Classe base com o mÃ©todo sendMessage
- **AgentController:** `/api/server/controllers/agents/request.js` - Controller que chama sendMessage
- **BuildEndpoint:** `/api/server/middleware/buildEndpointOption.js` - Middleware de preparaÃ§Ã£o
- **Routes:** `/api/server/routes/agents/chat.js` - DefiniÃ§Ã£o das rotas

### **âš ï¸ Caso Especial: Assistants API**

Os Assistants (OpenAI Assistants API) NÃƒO passam pelo `BaseClient.sendMessage()`. Eles tÃªm seu prÃ³prio fluxo:

1. **Entrada:** POST â†’ `/api/assistants/chat`
2. **Controller:** `/api/server/controllers/assistants/chatV1.js:49`
3. **ServiÃ§o:** `/api/server/services/AssistantService.js` - `runAssistant()`
4. **OpenAI API:** Chamada direta para API do OpenAI Assistants

**Para interceptar Assistants**, vocÃª precisaria modificar:
- `/api/server/controllers/assistants/chatV1.js` - Antes de chamar `runAssistant()`
- OU `/api/server/services/createRunBody.js` - Onde o corpo da requisiÃ§Ã£o Ã© montado

### **ğŸ“ Notas de ImplementaÃ§Ã£o:**

Este Ã© o local ideal para implementar sua lÃ³gica de enriquecimento com embeddings do quadrante antes que a requisiÃ§Ã£o seja enviada ao LLM. A interceptaÃ§Ã£o aqui garante que:

1. A maioria das requisiÃ§Ãµes sejam enriquecidas (exceto Assistants)
2. O contexto adicional seja incluÃ­do antes do processamento
3. A resposta do LLM jÃ¡ considere as informaÃ§Ãµes do quadrante
4. NÃ£o seja necessÃ¡rio modificar mÃºltiplos endpoints (exceto para Assistants)

### **ğŸ¯ RecomendaÃ§Ã£o Final:**

Para uma soluÃ§Ã£o completa que cubra TODOS os casos:

1. **Implemente no `BaseClient.sendMessage()`** para cobrir 90% dos casos (Agents, OpenAI, Anthropic, Google, Custom)
2. **Adicione interceptaÃ§Ã£o em `/api/server/controllers/assistants/chatV1.js`** para cobrir o caso dos Assistants
3. Considere criar um serviÃ§o centralizado de enriquecimento RAG que possa ser chamado de ambos os pontos